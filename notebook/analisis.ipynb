{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('datos.csv', sep=';' , encoding='latin-1')\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos['MENSAJES'] = datos['MENSAJES'].str.lower()\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos['MENSAJES'] = datos['MENSAJES'].apply(unidecode)\n",
    "datos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('perluniprops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('nonbreaking_prefixes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toktok = ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "datos['TOKENIZE'] = datos['MENSAJES'].apply(toktok.tokenize)\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('spanish'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            MENSAJES POLARIDAD  \\\n",
       "0          daya carolina ha creado el grupo grupo 4.    Neutro   \n",
       "1  rod?lf? chill ha creado el grupo grupo6-ia2b-a...    Neutro   \n",
       "2  por favor pongamos en la portada algo que teng...    Neutro   \n",
       "3  buenas tardes, que tal esta imagen. companero ...  Positivo   \n",
       "4  a mi me gusta, esperemos haber que dicen sus c...  Positivo   \n",
       "\n",
       "                                            TOKENIZE  \\\n",
       "0  [daya, carolina, ha, creado, el, grupo, grupo,...   \n",
       "1  [rod?lf, ?, chill, ha, creado, el, grupo, grup...   \n",
       "2  [por, favor, pongamos, en, la, portada, algo, ...   \n",
       "3  [buenas, tardes, ,, que, tal, esta, imagen., c...   \n",
       "4  [a, mi, me, gusta, ,, esperemos, haber, que, d...   \n",
       "\n",
       "                                          STOP WORDS  \n",
       "0       [daya, carolina, creado, grupo, grupo, 4, .]  \n",
       "1  [rod?lf, ?, chill, creado, grupo, grupo6-ia2b-...  \n",
       "2  [favor, pongamos, portada, relacion, asignatur...  \n",
       "3  [buenas, tardes, ,, tal, imagen., companero, a...  \n",
       "4  [gusta, ,, esperemos, haber, dicen, companeros...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MENSAJES</th>\n      <th>POLARIDAD</th>\n      <th>TOKENIZE</th>\n      <th>STOP WORDS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>daya carolina ha creado el grupo grupo 4.</td>\n      <td>Neutro</td>\n      <td>[daya, carolina, ha, creado, el, grupo, grupo,...</td>\n      <td>[daya, carolina, creado, grupo, grupo, 4, .]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rod?lf? chill ha creado el grupo grupo6-ia2b-a...</td>\n      <td>Neutro</td>\n      <td>[rod?lf, ?, chill, ha, creado, el, grupo, grup...</td>\n      <td>[rod?lf, ?, chill, creado, grupo, grupo6-ia2b-...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>por favor pongamos en la portada algo que teng...</td>\n      <td>Neutro</td>\n      <td>[por, favor, pongamos, en, la, portada, algo, ...</td>\n      <td>[favor, pongamos, portada, relacion, asignatur...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>buenas tardes, que tal esta imagen. companero ...</td>\n      <td>Positivo</td>\n      <td>[buenas, tardes, ,, que, tal, esta, imagen., c...</td>\n      <td>[buenas, tardes, ,, tal, imagen., companero, a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a mi me gusta, esperemos haber que dicen sus c...</td>\n      <td>Positivo</td>\n      <td>[a, mi, me, gusta, ,, esperemos, haber, que, d...</td>\n      <td>[gusta, ,, esperemos, haber, dicen, companeros...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "datos['STOP WORDS'] = datos['TOKENIZE'].apply(lambda msg: [item for item in msg if item not in stop_words])\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}